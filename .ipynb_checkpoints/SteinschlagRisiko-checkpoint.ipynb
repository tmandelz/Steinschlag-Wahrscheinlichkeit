{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4a05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from scipy import stats\n",
    "from numpy.random.mtrand import exponential\n",
    "from numpy.random import normal\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Global Variabels\n",
    "start_time = datetime.now()\n",
    "# Anzahl Durchgänge in der Monte Carlo Simulation\n",
    "sizeMonteCarloSim = 10000\n",
    "\n",
    "\n",
    "listfeatures_samples = pd.DataFrame()\n",
    "\n",
    "#Function for fitting a distribution on values of a column\n",
    "def FindmostfittingDistribution(MatrixColumn):\n",
    "\n",
    "    # List of available Distributions for fitting in scipy\n",
    "    list_of_dists = ['beta', 'cauchy', 'chi', 'chi2',\n",
    "                     'expon', 'logistic', 'norm', 'pareto', 't', 'uniform','gamma']\n",
    "\n",
    "    results = []\n",
    "    for i in list_of_dists:\n",
    "        dist = getattr(stats, i)\n",
    "        param = dist.fit(MatrixColumn)\n",
    "        a = stats.kstest(MatrixColumn, i, args=param)\n",
    "        results.append((i, a[0], a[1]))\n",
    "\n",
    "    results.sort(key=lambda x: float(x[2]), reverse=True)\n",
    "    for j in results:\n",
    "        print(\"{}: statistic={}, pvalue={}\".format(j[0], j[1], j[2]))\n",
    "        \n",
    "        \n",
    "\n",
    "#Function for Reading CSV File to Dataframe\n",
    "def ReadDataframe():\n",
    "    ##Read first CSV File\n",
    "    dataFile1 = pd.read_csv(\"out_1.csv\")\n",
    "    ##Read second CSV File\n",
    "    dataFile2 = pd.read_csv(\"out_2.csv\")\n",
    "\n",
    "    #Add Zone columns\n",
    "    dataFile1['zone']='1'\n",
    "    dataFile2['zone']='2'\n",
    "\n",
    "    #Append File 2 to File 1\n",
    "    mergedDataFile = dataFile1.append(dataFile2)\n",
    "    return mergedDataFile\n",
    "\n",
    "\n",
    "# Calculate and Update Columns\n",
    "def CalculateandUpdateColumns(mergedDataFile):\n",
    "    \n",
    "    #Add Energy in KJ column formula(KE=1/2mv^2)/1000 in m = kg and v = m/s\n",
    "    mergedDataFile['energy']=((mergedDataFile['mass']/2)*(mergedDataFile['velocity']**2) / 1000)\n",
    "\n",
    "    # Add Trigger if stone has fallen\n",
    "    mergedDataFile[\"Trigger\"] = np.where(mergedDataFile[\"zone\"] == 0, 0, 1) \n",
    "\n",
    "    # Create Datetime Column\n",
    "    mergedDataFile[\"DateTime\"] = pd.to_datetime(mergedDataFile['date'] + ' ' + mergedDataFile['timestamp'])\n",
    "\n",
    "    # Change Hour if two stones at same time\n",
    "    mergedDataFile = mergedDataFile.sort_values(by=['DateTime'])\n",
    "    mergedDataFile = mergedDataFile.reset_index(drop=True)\n",
    "    mergedDataFile.loc[1, 'timestamp'] = \"10:00\"\n",
    "    mergedDataFile.loc[44, 'timestamp'] = \"13:00\"\n",
    "    mergedDataFile.loc[89, 'timestamp'] = \"13:00\"\n",
    "\n",
    "    # Update Datetime Column\n",
    "    mergedDataFile[\"DateTime\"] = pd.to_datetime(mergedDataFile['date'] + ' ' + mergedDataFile['timestamp'])\n",
    "\n",
    "\n",
    "    # Fill missing hours\n",
    "    dfTimeSerie = mergedDataFile\n",
    "    dfTimeSerie = dfTimeSerie.set_index(mergedDataFile[\"DateTime\"])\n",
    "\n",
    "    dfTimeSerie = dfTimeSerie.resample('H').first().fillna(0)\n",
    "    dfTimeSerie['DateTime'] = dfTimeSerie.index\n",
    "\n",
    "    # Fill new missing days and hours in date and timestamp\n",
    "    dfTimeSerie[\"date\"] = dfTimeSerie[\"DateTime\"].dt.date\n",
    "    dfTimeSerie[\"timestamp\"] = dfTimeSerie[\"DateTime\"].dt.time\n",
    "\n",
    "    # Calculate Time before next Stone\n",
    "    mergedDataFileZone1 = mergedDataFile.loc[mergedDataFile['zone'] == \"1\"]\n",
    "    TimebeforeStone1 =mergedDataFileZone1[\"DateTime\"].diff()\n",
    "    mergedDataFileZone1[\"TimebeforeStone\"] = TimebeforeStone1.astype('timedelta64[h]').fillna(0)\n",
    "\n",
    "\n",
    "    mergedDataFileZone2 = mergedDataFile.loc[mergedDataFile['zone'] == \"2\"]\n",
    "    TimebeforeStone2 =mergedDataFileZone2[\"DateTime\"].diff()\n",
    "    mergedDataFileZone2[\"TimebeforeStone\"] = TimebeforeStone2.astype('timedelta64[h]').fillna(0)\n",
    "\n",
    "\n",
    "    mergedDataFile = mergedDataFileZone1.append(mergedDataFileZone2)\n",
    "\n",
    "    # Rolling 24h\n",
    "    dfTimeSerie[\"rollingEnergy24h\"] = dfTimeSerie[\"energy\"].rolling(24, min_periods=1).sum()\n",
    "    dfTimeSerie[\"rollingmass24h\"] = dfTimeSerie[\"mass\"].rolling(24, min_periods=1).sum()\n",
    "\n",
    "\n",
    "    # Calculate Breach\n",
    "    dfTimeSerie[\"BreachEnergy\"] = np.where(dfTimeSerie[\"energy\"] >= 1000, 1, 0)\n",
    "    dfTimeSerie[\"BreachFullNet\"] = np.where((dfTimeSerie[\"energy\"] >= 500) & (dfTimeSerie[\"rollingmass24h\"] >= 2000), 1, 0)\n",
    "    # Theoretisch müsste man dfTimeSerie[\"rollingmass24h\"] von der Reihe darüber nehmen, nun wird auch der neue Stein dazugezählt.\n",
    "    return mergedDataFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85d3a8f-22a8-417d-8f46-0b39bd3f955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-a27ea79e9265>:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mergedDataFileZone1[\"TimebeforeStone\"] = TimebeforeStone1.astype('timedelta64[h]').fillna(0)\n",
      "<ipython-input-1-a27ea79e9265>:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mergedDataFileZone2[\"TimebeforeStone\"] = TimebeforeStone2.astype('timedelta64[h]').fillna(0)\n"
     ]
    }
   ],
   "source": [
    "mergedDataFile =ReadDataframe()\n",
    "mergedDataFile =CalculateandUpdateColumns(mergedDataFile)\n",
    "dataFile1 = mergedDataFile.loc[mergedDataFile['zone'] == \"1\"]\n",
    "dataFile2 = mergedDataFile.loc[mergedDataFile['zone'] == \"2\"]\n",
    "\n",
    "Time_Import = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665fbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Definition der Verteilungsinformationen für die Zonen\n",
    "listfeatures_distributions_zone1 = [[\"mass\", \"exponential\"], [\n",
    "    \"velocity\", \"normal\"], [\"TimebeforeStone\", \"exponential\"]]\n",
    "listfeatures_distributions_zone2 = [[\"mass\", \"exponential\"], [\n",
    "    \"velocity\", \"normal\"], [\"TimebeforeStone\", \"exponential\"]]\n",
    "\n",
    "# Second Mainloop for zone calculations\n",
    "# Zone 1\n",
    "listfeatures_samples_zone_1 = pd.DataFrame()\n",
    "zoneindex = 0\n",
    "\n",
    "for featureDistribution in listfeatures_distributions_zone1:\n",
    "    zoneindex = 1\n",
    "    # calc fit dist features case when dist predefined\n",
    "    if (featureDistribution[1] == \"exponential\"):\n",
    "        explambda = mean(dataFile1[featureDistribution[0]])\n",
    "        # generate sample\n",
    "        sample = exponential(explambda, sizeMonteCarloSim)\n",
    "        listfeatures_samples_zone_1[featureDistribution[0]] = sample\n",
    "        featureDistribution_zone1 = np.append(featureDistribution, sample)\n",
    "    elif(featureDistribution[1] == \"normal\"):\n",
    "        meanTruncated = mean(dataFile1[featureDistribution[0]])\n",
    "        stdTruncated = np.std(dataFile1[featureDistribution[0]])\n",
    "        # generate sample\n",
    "        sample = normal(meanTruncated, stdTruncated,\n",
    "                        size=sizeMonteCarloSim)\n",
    "        listfeatures_samples_zone_1[featureDistribution[0]] = sample\n",
    "\n",
    "# Zone 2\n",
    "listfeatures_samples_zone_2 = pd.DataFrame()\n",
    "zoneindex = 0\n",
    "\n",
    "for featureDistribution in listfeatures_distributions_zone2:\n",
    "    zoneindex = 2\n",
    "    # calc fit dist features case when dist predefined\n",
    "    if (featureDistribution[1] == \"exponential\"):\n",
    "        explambda = mean(dataFile1[featureDistribution[0]])\n",
    "        # generate sample\n",
    "        sample = exponential(explambda, sizeMonteCarloSim)\n",
    "        listfeatures_samples_zone_2[featureDistribution[0]] = sample\n",
    "        listfeatures_distributions_zone2 = np.append(\n",
    "            featureDistribution, sample)\n",
    "    elif(featureDistribution[1] == \"normal\"):\n",
    "        meanTruncated = mean(dataFile1[featureDistribution[0]])\n",
    "        stdTruncated = np.std(dataFile1[featureDistribution[0]])\n",
    "        # generate sample\n",
    "        sample = normal(meanTruncated, stdTruncated,\n",
    "                        size=sizeMonteCarloSim)\n",
    "        listfeatures_samples_zone_2[featureDistribution[0]] = sample\n",
    "\n",
    "Timer_after_MonteCarlo = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee6c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of years: 34.0\n",
      "Number of BreachFullNet: 1\n",
      "Number of direct breakthrough: 0\n",
      "Duration: 0:00:00.320386\n",
      "Time Import 0:00:00.084150\n",
      "Time Monte Carlo 0:00:00.119782\n",
      "Time Calc Energy direct break 0:00:00.051195\n",
      "Time Cumsum1 0:00:00.002419\n",
      "Time Cumsum2 0:00:00.000987\n",
      "Time Merge 0:00:00.001509\n",
      "Time Merge cleaned 0:00:00.010635\n",
      "Time Calc Year 0:00:00.003339\n",
      "Time Calc Poss full Net 0:00:00.046370\n"
     ]
    }
   ],
   "source": [
    "# Berechnung der Energie der simulierten Steinschläge pro Zone\n",
    "listfeatures_samples_zone_1['energy'] = (\n",
    "    (listfeatures_samples_zone_1['mass']/2)*(listfeatures_samples_zone_1['velocity']**2) / 1000)\n",
    "listfeatures_samples_zone_2['energy'] = (\n",
    "    (listfeatures_samples_zone_2['mass']/2)*(listfeatures_samples_zone_2['velocity']**2) / 1000)\n",
    "# # Markierung der Steine, die mit der Energie das Netz durchschlagen haben\n",
    "listfeatures_samples_zone_1['direct_breakthrough'] = np.where(\n",
    "    (listfeatures_samples_zone_1[\"energy\"] >= 1000), 1, 0)\n",
    "listfeatures_samples_zone_2['direct_breakthrough'] = np.where(\n",
    "    (listfeatures_samples_zone_2[\"energy\"] >= 1000), 1, 0)\n",
    "\n",
    "listfeatures_samples_zone_1['Zone'] = 1\n",
    "listfeatures_samples_zone_2['Zone'] = 2\n",
    "\n",
    "Timer_after_Calc_Energy_directbreakthrough = datetime.now()\n",
    "\n",
    "# Berechnung Masse im Netz\n",
    "\n",
    "listfeatures_samples_zone_1[\"CumsumHoursbeforeStone\"] = listfeatures_samples_zone_1[\"TimebeforeStone\"].cumsum()\n",
    "Timer_after_Cumsum1 = datetime.now()\n",
    "listfeatures_samples_zone_2[\"CumsumHoursbeforeStone\"] = listfeatures_samples_zone_2[\"TimebeforeStone\"].cumsum()\n",
    "Timer_after_Cumsum2 = datetime.now()\n",
    "\n",
    "\n",
    "listfeatures_samples = listfeatures_samples_zone_1.append(listfeatures_samples_zone_2, ignore_index=True)\n",
    "Timer_after_Merge = datetime.now()\n",
    "\n",
    "\n",
    "listfeatures_samples = listfeatures_samples.sort_values(by='CumsumHoursbeforeStone')\n",
    "listfeatures_samples = listfeatures_samples.reset_index(drop=True)\n",
    "Timer_after_Merge_clean = datetime.now()\n",
    "\n",
    "\n",
    "listfeatures_samples[\"Year\"] = listfeatures_samples['CumsumHoursbeforeStone'].floordiv(8760)\n",
    "Timer_after_Calc_Year = datetime.now()\n",
    "\n",
    "\n",
    "# Berechnet, wieviel Masse pro Tag im Netz ist, aber nicht, ob es wegen dem letzten gerissen ist...\n",
    "listfeatures_samples[\"Tag\"] = listfeatures_samples['CumsumHoursbeforeStone'] // 24\n",
    "Netzvoll = listfeatures_samples.groupby(\"Tag\")[\"mass\"].agg(\"sum\")\n",
    "Netzvoll = pd.DataFrame({'Tag': Netzvoll.index, 'Tagesmasse': Netzvoll.values})\n",
    "listfeatures_samples = listfeatures_samples.merge(\n",
    "    Netzvoll, how=\"left\", on=\"Tag\")\n",
    "listfeatures_samples[\"PossibleBreachFullNet\"] = np.where(\n",
    "    (listfeatures_samples[\"energy\"] >= 500) & (listfeatures_samples[\"Tagesmasse\"] >= 2000), 1, 0)\n",
    "\n",
    "\n",
    "CountBreachFullNet = 0\n",
    "ListPossibleBrechFullNet = listfeatures_samples[listfeatures_samples[\"PossibleBreachFullNet\"] == 1]\n",
    "ListPossibleBrechFullNet = ListPossibleBrechFullNet.reset_index()\n",
    "for i in range(len(ListPossibleBrechFullNet)):\n",
    "    Day = ListPossibleBrechFullNet.loc[i, \"Tag\"]\n",
    "    ToCheck = listfeatures_samples[listfeatures_samples[\"Tag\"] == Day]\n",
    "    ToCheck = ToCheck.reset_index()\n",
    "    ToCheck[\"CumsumMass\"] = ToCheck[\"mass\"].shift().cumsum()\n",
    "    for i in range(len(ToCheck)):\n",
    "        if ToCheck.loc[i, \"direct_breakthrough\"] == 1:\n",
    "            break  # break weil wenn das Netz durchbrochen ist, die Strasse gesperrt wird\n",
    "        else:\n",
    "            if (ToCheck.loc[i, \"energy\"] >= 500) & (ToCheck.loc[i, \"CumsumMass\"] >= 2000):\n",
    "                CountBreachFullNet += 1\n",
    "                break\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Number of years:\", listfeatures_samples[\"Year\"].max())\n",
    "print(\"Number of BreachFullNet:\", CountBreachFullNet)\n",
    "print(\"Number of direct breakthrough:\",\n",
    "      listfeatures_samples[\"direct_breakthrough\"].sum())\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n",
    "print(\"Time Import\", Time_Import - start_time)\n",
    "print(\"Time Monte Carlo\", Timer_after_MonteCarlo - Time_Import)\n",
    "print(\"Time Calc Energy direct break\",\n",
    "      Timer_after_Calc_Energy_directbreakthrough - Timer_after_MonteCarlo)\n",
    "print(\"Time Cumsum1\", Timer_after_Cumsum1 -\n",
    "      Timer_after_Calc_Energy_directbreakthrough)\n",
    "print(\"Time Cumsum2\", Timer_after_Cumsum2 - Timer_after_Cumsum1)\n",
    "print(\"Time Merge\", Timer_after_Merge - Timer_after_Cumsum2)\n",
    "print(\"Time Merge cleaned\", Timer_after_Merge_clean - Timer_after_Merge)\n",
    "print(\"Time Calc Year\", Timer_after_Calc_Year - Timer_after_Merge_clean)\n",
    "print(\"Time Calc Poss full Net\", end_time - Timer_after_Calc_Year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84dfacc-de0e-4931-8b2d-1778444f3867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
